# clusterBMA::clusterBMA()

# input arguments: input_data = DATA FRAME of input data for clustering; cluster_prob_matrices = list of allocation probability matrices from clustering solutions;
# n_final_clust = number of clusters for final BMA solution (e.g. maximum number of clusters across any input solution; or desired final number for K based on
# clustering internal validation criteria)

# Each entry in cluster_prob_matrices should be a NxK_m matrix A_m where N = number of datapoints (rows), and K_m = number of clusters (columns).
# Each entry A_ik represents the probability that point i is allocated to cluster k in each solution

# For 'hard' clustering solutions (1 or 0 probability of cluster allocation) such as k-means or hierarchical clustering, \
# the allocation matrix can be created using the function clusterBMA::hard_to_prob_fn()

# For 'soft' clustering solutions e.g. GMM, this is usually accessible from the model output. E.g. the object cluster_proba within the result from
# ClusterR::predictGMM() on a GMM object produced from ClusterR::GMM()




# suggest adding BMA outputs to original input_data DF for plotting/further analyses
# e.g.
# # save cluster allocations for plotting DF
# input_data$bma_cluster_labs <- bma_cluster_labels_df$alloc_ordered
#
# input_data$bma_cluster_probability <- bma_cluster_labels_df$alloc_prob
#
# # save cluster allocation uncertainty for plotting DF
# input_data$bma_cluster_uncertainty <- bma_cluster_labels_df$alloc_uncertainty

#' clusterBMA - Apply Bayesian model averaging to combine multiple clustering solutions for a given dataset
#'
#' For detailed example, see vignette(clusterBMA_vignette, package = "clusterBMA")
#'
#' Each entry in cluster_prob_matrices should be a NxK_m matrix A_m where N = number of datapoints (rows), and K_m = number of clusters (columns).
#' Each entry A_ik represents the probability that point i is allocated to cluster k in each solution
#'
#' For 'hard' clustering solutions (1 or 0 probability of cluster allocation) such as k-means or hierarchical clustering, the allocation matrix can be created using the function clusterBMA::hard_to_prob_fn()
#'
#' For 'soft' clustering solutions e.g. GMM, this is usually accessible from the model output. E.g. the object cluster_proba within the result from ClusterR::predictGMM() on a GMM object produced from ClusterR::GMM()
#'
#' `wt_crit_name` is the Clustering Internal Validation Index (CIVI) used to approximate posterior model probability. The default selection is the Calinski Harabasz index. Indices can be chosen from the list available in `clusterCrit::getCriteriaNames(isInternal=T)`
#' See clusterCrit documentation for details on other available CIVIs: https://rdrr.io/cran/clusterCrit/f/inst/doc/clusterCrit.pdf
#'
#' Outputs in results list can be indexed like test_bma_results[[1]] for consensus matrix, test_bma_results[[3]] for cluster labels and probability/uncertainty, etc. Details in README on Github, and in package vignette
#'
#' @param input_data Data frame or matrix of original input data used for clustering algorithms
#' @param cluster_prob_matrices LIST of allocation probability matrices from clustering solutions. For 'soft' clustering algorithms like ClusterR::GMM(), this is often an available output - e.g. from the object generated by `ClusterR::predict_GMM()` it is stored in $cluster_proba. For 'hard' clustering algorithms like k-means, a helper function `clusterBMA::hard_to_prob_fn()` can be used to convert a vector of cluster allocation labels to a NxK matrix of cluster allocation probabilities. The number of clusters K can vary between input models.
#' @param n_final_clust Number of clusters for final BMA solution (Can be chosen as e.g. maximum number of clusters across any input solution, or desired final number for K based on clustering internal validation criteria). Final number of clusters may be lower than this selected maximum due to L2 regularisation which can empty redundant clusters as part of the symmetric simplex matrix factorisation step.
#' @param prior_weights (Optional) Vector of weights assigning manual prior weight to each input solution. If left blank, equal prior weights are assigned by default.
#' @param wt_crit_name Clustering Internal Validation Index (CIVI) used to approximate posterior model probability. The default selection is the Calinski Harabasz index. Indices can be chosen from the list available in `clusterCrit::getCriteriaNames(isInternal=T)`
#' @param wt_crit_direction Direction of selected CIVI - "max" if to be maximised, "min" if to be minimised. Set to "max" by default for Calinski Harabasz index. See page 21 of clusterCrit manual https://rdrr.io/cran/clusterCrit/f/inst/doc/clusterCrit.pdf
#'
#' @return Returns a list of outputs from clusterBMA. \enumerate{\item Consensus matrix - element-wise weighted average of input similarity matrices \item Allocation probability matrix - clusterBMA cluster allocation probabilities \item clusterBMA cluster LABELS with associated probability and uncertainty. Key output for most users. \item Table counting points in each averaged cluster (crisp projection to maximum probability clusters for each point) \item Weights calculated from CIVI for each algorithm. \item weights multiplied by prior probabilities - should be the same as output [5] if prior model weights are set to be equal (default). \item Heatmap of Consensus matrix}
#' @export
#'
clusterBMA <- function(input_data,cluster_prob_matrices,n_final_clust,prior_weights="equal", wt_crit_name="Calinski_Harabasz",wt_crit_direction = "max"){

  n_models <- length(cluster_prob_matrices)

  if(prior_weights == "equal"){
    prior_vec <- rep(1/n_models,n_models) #e.g. c(0.2, 0.2, 0.2) for M = 3
  } else {
    prior_vec <- prior_weights # user-supplied vector of prior weights that sum to 1, of length M = n. of models
  }


  # can suppress warnings (coming up because of outdated python syntax but it still works fine)
  #oldw <- getOption("warn")
  #options(warn = -1)



  clusterBMA_use_condaenv() #specify conda environment to use

  #coerce input data to data frame
  input_data <- as.data.frame(input_data)

  # conda_existing <- reticulate::conda_list()
  # if(!("clusterBMA-pyenv"%in% conda_existing$name)){
  #   stop("Please run clusterBMA_initial_python_setup() first to install Python 3.7.9 and Tensorflow 1.15.5 in a dedicated miniconda environment, then restart your R session. You may want to save any data/variables in the environment before installing & restarting.")
  #   }



  #calculate similarity matrix for each model
  similarity_matrix_list <- vector(mode = "list", length = n_models)

  for (i in 1:n_models){
    similarity_matrix_list[[i]] <- sim_mat_fn(cluster_prob_matrices[[i]])
  }

  # calculate cluster allocation (max prob) vectors

  cluster_labels_list <- vector(mode = "list", length = n_models)

  for (i in 1:n_models){

    temp_pthf <- prob_to_hard_fn(soft_alloc_matrix = cluster_prob_matrices[[i]])

    cluster_labels_list[[i]] <- temp_pthf[[1]]$alloc_vector
  }

  cluster_labels_df <- as.data.frame(cluster_labels_list)


  # calculate weights
  # Changing to try using new_weight_fn

  bma_weights_df <- new_weight_fn(input_data=input_data,cluster_label_df = cluster_labels_df,n_sols = n_models, wt_crit_name = wt_crit_name, wt_crit_direction = wt_crit_direction)
  #bma_weights_df <- ch_xb_weight_fn(input_data=input_data,cluster_label_df = cluster_labels_df,n_sols = n_models)


  # calculate BMA results!
  bma_results <- consensus_matrix_fn(sim_mat_list = similarity_matrix_list,algo_weights=bma_weights_df$W_m,n_final_clust=n_final_clust, prior_vec=prior_vec)


  #consensus_matrix <- bma_results[[1]]
  #bma_probabilities <- bma_results[[2]]
  #bma_cluster_labels_df <- bma_results[[3]]
  #bma_allocs_table <- bma_results[[4]]


  #options(warn = oldw) #possibility to suppress warnings if desired

  return(bma_results)
}
